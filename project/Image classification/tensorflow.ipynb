{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04054d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 424 images belonging to 7 classes.\n",
      "Found 102 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "rootPath = './dataset/train'\n",
    "\n",
    "imageGenerator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[.2, .2],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=.2\n",
    ")\n",
    "\n",
    "trainGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'digital_img'),\n",
    "    target_size=(64, 64),\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validationGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'digital_img'),\n",
    "    target_size=(64, 64),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae4996d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: {'d1_1': 0, 'd1_2': 1, 'd1_3': 2, 'db_1': 3, 'db_2': 4, 'db_3': 5, 'foun': 6}\n",
      "Label to class: {0: 'd1_1', 1: 'd1_2', 2: 'd1_3', 3: 'db_1', 4: 'db_2', 5: 'db_3', 6: 'foun'}\n"
     ]
    }
   ],
   "source": [
    "class_labels = trainGen.class_indices\n",
    "print(\"Class labels:\", class_labels)\n",
    "\n",
    "# 클래스 레이블과 클래스 이름을 반전시켜 딕셔너리 생성\n",
    "label_to_class = {v: k for k, v in class_labels.items()}\n",
    "print(\"Label to class:\", label_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42604178",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 32, 32, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               2097664   \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2254375 (8.60 MB)\n",
      "Trainable params: 2254375 (8.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.InputLayer(input_shape=(64, 64, 3)))\n",
    "model.add(layers.Conv2D(16, (3, 3), (1, 1), 'same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), (1, 1), 'same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), (1, 1), 'same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a767bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263fdef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmh\\AppData\\Local\\Temp\\ipykernel_13784\\2161297457.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "15/14 [==============================] - ETA: 0s - loss: 0.4484 - acc: 0.1548WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 14.9375 batches). You may need to use the repeat() function when building your dataset.\n",
      "14/14 [==============================] - 18s 1s/step - loss: 0.4484 - acc: 0.1548 - val_loss: 0.4465 - val_acc: 0.2083\n",
      "Epoch 2/32\n",
      "14/14 [==============================] - 13s 837ms/step - loss: 0.4063 - acc: 0.2238\n",
      "Epoch 3/32\n",
      "14/14 [==============================] - 13s 858ms/step - loss: 0.4057 - acc: 0.2197\n",
      "Epoch 4/32\n",
      "14/14 [==============================] - 13s 833ms/step - loss: 0.3939 - acc: 0.2008\n",
      "Epoch 5/32\n",
      "14/14 [==============================] - 12s 829ms/step - loss: 0.3704 - acc: 0.3138\n",
      "Epoch 6/32\n",
      "14/14 [==============================] - 12s 831ms/step - loss: 0.3031 - acc: 0.4728\n",
      "Epoch 7/32\n",
      "14/14 [==============================] - 12s 828ms/step - loss: 0.2370 - acc: 0.6464\n",
      "Epoch 8/32\n",
      "14/14 [==============================] - 13s 841ms/step - loss: 0.1856 - acc: 0.7134\n",
      "Epoch 9/32\n",
      "14/14 [==============================] - 13s 847ms/step - loss: 0.1741 - acc: 0.7490\n",
      "Epoch 10/32\n",
      "14/14 [==============================] - 13s 852ms/step - loss: 0.1472 - acc: 0.7657\n",
      "Epoch 11/32\n",
      "14/14 [==============================] - 13s 859ms/step - loss: 0.1100 - acc: 0.8556\n",
      "Epoch 12/32\n",
      "14/14 [==============================] - 13s 859ms/step - loss: 0.0891 - acc: 0.8828\n",
      "Epoch 13/32\n",
      "14/14 [==============================] - 14s 910ms/step - loss: 0.0783 - acc: 0.9121\n",
      "Epoch 14/32\n",
      "14/14 [==============================] - 13s 836ms/step - loss: 0.0456 - acc: 0.9477\n",
      "Epoch 15/32\n",
      "14/14 [==============================] - 13s 836ms/step - loss: 0.0488 - acc: 0.9519\n",
      "Epoch 16/32\n",
      "14/14 [==============================] - 13s 838ms/step - loss: 0.0573 - acc: 0.9247\n",
      "Epoch 17/32\n",
      "14/14 [==============================] - 13s 839ms/step - loss: 0.0404 - acc: 0.9582\n",
      "Epoch 18/32\n",
      "14/14 [==============================] - 13s 846ms/step - loss: 0.0396 - acc: 0.9519\n",
      "Epoch 19/32\n",
      "14/14 [==============================] - 13s 836ms/step - loss: 0.0321 - acc: 0.9644\n",
      "Epoch 20/32\n",
      "14/14 [==============================] - 13s 835ms/step - loss: 0.0310 - acc: 0.9623\n",
      "Epoch 21/32\n",
      "14/14 [==============================] - 12s 831ms/step - loss: 0.0163 - acc: 0.9812\n",
      "Epoch 22/32\n",
      "14/14 [==============================] - 13s 840ms/step - loss: 0.0145 - acc: 0.9895\n",
      "Epoch 23/32\n",
      "14/14 [==============================] - 13s 834ms/step - loss: 0.0135 - acc: 0.9854\n",
      "Epoch 24/32\n",
      "14/14 [==============================] - 12s 834ms/step - loss: 0.0088 - acc: 0.9895\n",
      "Epoch 25/32\n",
      "14/14 [==============================] - 13s 836ms/step - loss: 0.0118 - acc: 0.9874\n",
      "Epoch 26/32\n",
      "14/14 [==============================] - 13s 837ms/step - loss: 0.0091 - acc: 0.9916\n",
      "Epoch 27/32\n",
      "14/14 [==============================] - 12s 826ms/step - loss: 0.0079 - acc: 0.9916\n",
      "Epoch 28/32\n",
      "14/14 [==============================] - 12s 831ms/step - loss: 0.0047 - acc: 0.9979\n",
      "Epoch 29/32\n",
      "14/14 [==============================] - 12s 825ms/step - loss: 0.0081 - acc: 0.9874\n",
      "Epoch 30/32\n",
      "14/14 [==============================] - 13s 848ms/step - loss: 0.0055 - acc: 0.9958\n",
      "Epoch 31/32\n",
      "14/14 [==============================] - 13s 836ms/step - loss: 0.0050 - acc: 0.9958\n",
      "Epoch 32/32\n",
      "14/14 [==============================] - 12s 832ms/step - loss: 0.0096 - acc: 0.9916\n"
     ]
    }
   ],
   "source": [
    "epochs = 32\n",
    "history = model.fit(\n",
    "    trainGen, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=trainGen.samples / epochs, \n",
    "    validation_data=validationGen,\n",
    "    validation_steps=trainGen.samples / epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae3e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f07d0f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (32,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m\n\u001b[0;32m     26\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 30\u001b[0m show_graph(history)\n",
      "Cell \u001b[1;32mIn[20], line 13\u001b[0m, in \u001b[0;36mshow_graph\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m121\u001b[39m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, accuracy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, val_accuracy, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining and validation accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3579\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3580\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3581\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3583\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3584\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (32,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAH5CAYAAADENpm/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqGElEQVR4nO3df5DcdX0/8NfmIBco3AEGLpe7g0OpUAoEGuSa2rOhXAnaSUPPzERwJE0RRxudhIwVopJItYRidY6WKFPU2j8aQNPD/oCCTJpgnEYZw2TUjkRBaC7hEsAOdxiE4N7n+8d+78hxl+Q2u7l9797jMbOz2fe+P7uv/fjRe/r+fD7vdy7LsiwAAEjCtEoXAADAG4QzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkJDjKl3ARAwNDcVzzz0XJ598cuRyuUqXAwBQlCzL4uWXX47Zs2fHtGmHHxurinD23HPPRVtbW6XLAAAoSV9fX7S2th62T1WEs5NPPjkiCj+ooaGhwtUAABRncHAw2traRjLN4VRFOBs+ldnQ0CCcAQBVayKXZ7khAAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABJSdDj7zne+EwsXLozZs2dHLpeLb33rW0fcZsuWLfE7v/M7UV9fH+ecc058/etfP4pSAYCyyecjtmyJuPfewnM+X+mK+P+KDmf79++POXPmxPr16yfU/5lnnok//uM/jssvvzx27NgRK1eujA9+8IPxyCOPFF0sAFAGvb0R7e0Rl18ece21hef29kL7ZCo1INZowMxlWZYd9ca5XDzwwANx9dVXH7LPTTfdFA8++GD8+Mc/Hml73/veFy+99FI8/PDDE/qewcHBaGxsjIGBgWhoaDjacgGA3t6IxYsj3vznP5crPG/cGNHdPTl1rFgRsXv3G22trRF33jmx7y91+0lWTJY55tecbdu2Lbq6uka1LViwILZt23bIbV577bUYHBwc9QCAmlGpEaN8vhBoxhuXGW5bufLYj0ANB8SDg1VExJ49hfYjjeCVuv3BEhx9O+bhbO/evdHU1DSqrampKQYHB+NXv/rVuNusW7cuGhsbRx5tbW3HukwAjrVU/ghWuo5STymWsv3WrWMDzcGyLKKvr9DvWCk1IJYzYKZyevdNkrxbc/Xq1TEwMDDy6Ovrq3RJAJQilT+C5aijlHBX6RGj/v6J1TmRfke7H0oNiOUKmOUcfSuzYx7OZs2aFfv27RvVtm/fvmhoaIgTTjhh3G3q6+ujoaFh1AOAKpXKH8Fy1FFKuEthxKi5+ch1TqRfKfuh1IBYjoCZyundQzjm4WzevHmxadOmUW2PPvpozJs371h/NQCVVu4/gpW81qrUcJfCiFFnZ+Gi+eGL/98sl4toayv0O5RS90OpAbEcATOF07uHUXQ4++Uvfxk7duyIHTt2RERhqowdO3bErl27IqJwSvK6664b6f/hD384fv7zn8cnPvGJePLJJ+NLX/pSfOMb34gbb7yxPL8AgHSV849gJa+1Kke4S2HEqK6ucDdjxNiANvy6p6fQbzzl2A+lBsRyBMxynt49BooOZz/4wQ/ikksuiUsuuSQiIlatWhWXXHJJrFmzJiIi+vv7R4JaRMTZZ58dDz74YDz66KMxZ86c+MIXvhBf+cpXYsGCBWX6CQBMiqMZtSrXH8FKX2tVjpCZwohRRGGaiY0bI1paRre3th55Go1y7IdSA2Kp20eUb18eK1kVGBgYyCIiGxgYqHQpAFPTv/xLlrW2Zlnhz2/h0dpaaD+czZtHb3Oox+bNh/6MX/967Hcf/MjlsqytrdDvWNWxYcPEtt+w4ci/I5c7ut9R6vbjfd7mzYWaN2+e2Hbl2A/Dxjum2tqOfEyVY/ty78sJKCbLJHm3JgAJKWXUqhynoFK41qocIy0pjBi9+fPmz4+45prC80S2K+eIU3d3xLPPRmzeHLFhQ+H5mWcmPoFsKduXe1+WW9ki4TFk5AygQsoxavUv/1Lo9+ZRiuG2I410lGu0ppQ6yjnSUskRo1JVYMTpmJrEfVlMlilp+abJYvkmgArZsqVw4f2RbN5cGH05lPGW2mlrK4xOHGmko1w1lFrH8AhixOgL4o9m2aN8vjDS199fGGXq7CxulKbU7UtRzv2Qgknal8VkGeEMgEO7997CnZFHsmFD4fTY4RztH8F8vnBX5p49498lmMsVTlk+88zEP+9o/xiXEu5qif1QNOEMgPIo56hVKVIarankqFVK7IeiCGcAlEe5R61KYbSGKlZMljlukmoCoBSVGqUYvqtt8eJCEBtv1Gqy7mrr7o5YtMhoDTVPOANI3XgjRq2thdA0GRegD09aOl4Nkz1qNTz9A9QwpzUBUjZ8rdWb/6e6mGutyhHuIlxjBCVwzRlAOVUqlAxf73WoCVgncr1XOcIdULJisowVAgAOp5TFtkuVwmLdwKQTzgAOpdTFtkuVwmLdwKRzQwCQtkqeUjzcqFMuVxh1WrToyPUc7W8odR3DUsMdUBFGzoB0VfMpxWGl/IYUFusGJp1wBhw7+Xxhhvl77y08F3NtU7WfUowo/TcMzzEWMTagTWSOsVLDHVARwhlwbJQyYpTCheyljjqV6zcMzzHW0jK6vbX1yHdalhrugIoQzoDyK3XEKIUL2UsddSrnb+jujnj22cL6lRs2FJ6feWZiU2CUEu6AinBDAFBe5biQPoUL2Utdtqjcv6GUmfEtewRVxcgZUF7lGDFK5UL2UkadUvkNw4bD3TXXFJ4FM0iWkTOgvMoxYjR8SnHPnvFH4IZnxp+MC9mPdtQppd8AVBUjZ0B5lWPEKLUL2Y9m1Cm13wBUDeEMKK9yTd9QCxey18JvACadhc+B8hu+WzNi/AvpiwkmlVohoJxq4TcAJSkmywhnwLHR21u4a/PgmwPa2gqn8owYAVNMMVnGDQHAsWH6BoCjIpwBx04pc3MBTFHCGVDbXO8FVBnhDKhd41331tpamOLCdW9AokylAdSmUtf3BKgQ4QyoPUda3zOisL5nPj+pZQFMhHAG1J5yrO8JUCHCGVB7yrG+J0CFuCEAOLRqvdOxHOt7AlSIkTNgfL29Ee3tEZdfHnHttYXn9vbquJC+XOt7AlSAcAaMVe13OtbVFabLiBgb0IZf9/RUxyggMOUIZ8BotXKnY3d3YYH1lpbR7a2txS28DjDJXHMGjFbMnY6pL81kfU+gCglnwGi1dqej9T2BKuO0JjCaOx0BKko4A0ZzpyNARQlnwGjudASoKOEMGMudjgAV44YAYHzudASoCOEMODR3OgJMOqc1AQASIpwBACREOAMASIhrzqBW5fMu5geoQsIZ1KLe3sLi5QevkdnaWpi/zDQYAElzWhNqTW9vxOLFYxcv37On0N7bW5m6AJgQ4QxqST5fGDHLsrHvDbetXFnoB0CShDOoJVu3jh0xO1iWRfT1FfoBkCThDGpJf395+wEw6YQzqCXNzeXtB8CkE86glnR2Fu7KzOXGfz+Xi2hrK/QDIEnCGdSSurrCdBkRYwPa8OueHvOdASRMOINa090dsXFjREvL6PbW1kK7ec4AkmYSWqhF3d0RixZZIQCgCglnUKvq6iLmz690FQAUyWlNAICEGDmDVFm4HGBKEs4gRRYuB5iynNaE1Fi4HGBKE84gJRYuB5jyhDNIiYXLAaY84QxSYuFygClPOIOUWLgcYMoTziAlFi4HmPKEM0iJhcsBpjzhDFJj4XKAKc0ktJAiC5cDTFnCGaTKwuUAU5LTmgAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAk5qnC2fv36aG9vjxkzZkRHR0c8/vjjh+3f09MT5557bpxwwgnR1tYWN954Y7z66qtHVTAAQC0rOpzdf//9sWrVqli7dm088cQTMWfOnFiwYEE8//zz4/bfsGFD3HzzzbF27dr4yU9+El/96lfj/vvvj09+8pMlFw8AUGuKDmdf/OIX44Ybbohly5bF+eefH3fffXeceOKJ8bWvfW3c/v/93/8d73znO+Paa6+N9vb2uPLKK+Oaa6454mgbAMBUVFQ4O3DgQGzfvj26urre+IBp06Krqyu2bds27ja/93u/F9u3bx8JYz//+c/joYceive85z2H/J7XXnstBgcHRz0AAKaC44rp/OKLL0Y+n4+mpqZR7U1NTfHkk0+Ou821114bL774Yvz+7/9+ZFkWv/71r+PDH/7wYU9rrlu3Lm699dZiSgMAqAnH/G7NLVu2xG233RZf+tKX4oknnoje3t548MEH47Of/ewht1m9enUMDAyMPPr6+o51mQAASShq5GzmzJlRV1cX+/btG9W+b9++mDVr1rjb3HLLLfGBD3wgPvjBD0ZExIUXXhj79++PD33oQ/GpT30qpk0bmw/r6+ujvr6+mNIAAGpCUSNn06dPj7lz58amTZtG2oaGhmLTpk0xb968cbd55ZVXxgSwurq6iIjIsqzYegEAalpRI2cREatWrYqlS5fGpZdeGpdddln09PTE/v37Y9myZRERcd1110VLS0usW7cuIiIWLlwYX/ziF+OSSy6Jjo6OeOqpp+KWW26JhQsXjoQ0AAAKig5nS5YsiRdeeCHWrFkTe/fujYsvvjgefvjhkZsEdu3aNWqk7NOf/nTkcrn49Kc/HXv27InTTz89Fi5cGH/9139dvl8BAFAjclkVnFscHByMxsbGGBgYiIaGhkqXAwBQlGKyjLU1AQASIpwBACREOAMASIhwBgCQEOEMACAhRU+lAUxAPh+xdWtEf39Ec3NEZ2eEef0AmADhDMqttzdixYqI3bvfaGttjbjzzoju7srVBUBVcFoTyqm3N2Lx4tHBLCJiz55Ce29vZeoCoGoIZ1Au+XxhxGy8eZ2H21auLPQDgEMQzqBctm4dO2J2sCyL6Osr9AOAQxDOoFz6+8vbD4ApSTiDcmluLm8/AKYk4QzKpbOzcFdmLjf++7lcRFtboR8AHIJwBuPJ5yO2bIm4997C80Qu4q+rK0yXETE2oA2/7ukx3xkAhyWcwZv19ka0t0dcfnnEtdcWntvbJzYNRnd3xMaNES0to9tbWwvt5jkD4AhyWTbeff9pGRwcjMbGxhgYGIiGhoZKl0MtG56n7M3/tRge+ZpowLJCAAAHKSbLCGcwLJ8vjJAdajqMXK4wAvbMM4IWAEUpJss4rQnDzFMGQAKEMxhmnjIAEiCcwTDzlAGQAOEMhpmnDIAECGcwzDxlACRAOIODmacMgAo7rtIFQHK6uyMWLTJPGQAVIZzBeOrqIubPr3QVAExBTmsCACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhJhKg9qTz5ujDICqJZxRW3p7I1asiNi9+4221tbCskxm9wegCjitSe3o7Y1YvHh0MIuI2LOn0N7bW5m6AKAIwhm1IZ8vjJhl2dj3httWriz0A4CECWfUhq1bx46YHSzLIvr6Cv0AIGHCGbWhv7+8/QCgQoQzakNzc3n7AUCFCGfUhs7Owl2Zudz47+dyEW1thX4AkDDhjNpQV1eYLiNibEAbft3TY74zAJInnFE7ursjNm6MaGkZ3d7aWmg3zxkAVcAktNSW7u6IRYusEABA1RLOqD11dRHz51e6CgA4Kk5rAgAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQo6rdAEwRj4fsXVrRH9/RHNzRGdnRF1dpasCgEkhnJGW3t6IFSsidu9+o621NeLOOyO6uytXFwBMEqc1SUdvb8TixaODWUTEnj2F9t7eytQFAJNIOCMN+XxhxCzLxr433LZyZaEfANQw4Yw0bN06dsTsYFkW0ddX6AcANUw4Iw39/eXtBwBVSjgjDc3N5e0HAFVKOCMNnZ2FuzJzufHfz+Ui2toK/QCghglnpKGurjBdRsTYgDb8uqfHfGcA1DzhjHR0d0ds3BjR0jK6vbW10G6eMwCmAJPQkpbu7ohFi6wQAMCUJZyRnrq6iPnzK10FAFSE05oAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQkKMKZ+vXr4/29vaYMWNGdHR0xOOPP37Y/i+99FIsX748mpubo76+Pt7+9rfHQw89dFQFAwDUsuOK3eD++++PVatWxd133x0dHR3R09MTCxYsiJ07d8YZZ5wxpv+BAwfij/7oj+KMM86IjRs3RktLS/zv//5vnHLKKeWoHwCgpuSyLMuK2aCjoyPe8Y53xF133RUREUNDQ9HW1hYf+9jH4uabbx7T/+67747Pf/7z8eSTT8bxxx9/VEUODg5GY2NjDAwMRENDw1F9BgBApRSTZYo6rXngwIHYvn17dHV1vfEB06ZFV1dXbNu2bdxt/u3f/i3mzZsXy5cvj6amprjgggvitttui3w+f8jvee2112JwcHDUAwBgKigqnL344ouRz+ejqalpVHtTU1Ps3bt33G1+/vOfx8aNGyOfz8dDDz0Ut9xyS3zhC1+Iz33uc4f8nnXr1kVjY+PIo62trZgyAQCq1jG/W3NoaCjOOOOM+Id/+IeYO3duLFmyJD71qU/F3XfffchtVq9eHQMDAyOPvr6+Y10mAEASirohYObMmVFXVxf79u0b1b5v376YNWvWuNs0NzfH8ccfH3V1dSNtv/VbvxV79+6NAwcOxPTp08dsU19fH/X19cWUBgBQE4oaOZs+fXrMnTs3Nm3aNNI2NDQUmzZtinnz5o27zTvf+c546qmnYmhoaKTtpz/9aTQ3N48bzAAAprKiT2uuWrUq7rnnnvinf/qn+MlPfhIf+chHYv/+/bFs2bKIiLjuuuti9erVI/0/8pGPxP/93//FihUr4qc//Wk8+OCDcdttt8Xy5cvL9ysAAGpE0fOcLVmyJF544YVYs2ZN7N27Ny6++OJ4+OGHR24S2LVrV0yb9kbma2tri0ceeSRuvPHGuOiii6KlpSVWrFgRN910U/l+BQBAjSh6nrNKMM8ZAFDNjtk8ZwAAHFvCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICEHFfpAqgx+XzE1q0R/f0Rzc0RnZ0RdXWVrgoAqoZwRvn09kasWBGxe/cbba2tEXfeGdHdXbm6AKCKOK1JefT2RixePDqYRUTs2VNo7+2tTF0AUGWEM0qXzxdGzLJs7HvDbStXFvoBAIclnFG6rVvHjpgdLMsi+voK/QCAwxLOKF1/f3n7AcAUJpxRuubm8vYDgClMOKN0nZ2FuzJzufHfz+Ui2toK/QCAwxLOKF1dXWG6jIixAW34dU+P+c4AYAKEM8qjuzti48aIlpbR7a2thXbznAHAhJiElvLp7o5YtMgKAQBQAuGM8qqri5g/v9JVAEDVcloTACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhRxXO1q9fH+3t7TFjxozo6OiIxx9/fELb3XfffZHL5eLqq68+mq8FAKh5RYez+++/P1atWhVr166NJ554IubMmRMLFiyI559//rDbPfvss/Hxj388Ojs7j7pYAIBaV3Q4++IXvxg33HBDLFu2LM4///y4++6748QTT4yvfe1rh9wmn8/H+9///rj11lvjrW99a0kFAwDUsqLC2YEDB2L79u3R1dX1xgdMmxZdXV2xbdu2Q273V3/1V3HGGWfE9ddfP6Hvee2112JwcHDUAwBgKigqnL344ouRz+ejqalpVHtTU1Ps3bt33G2++93vxle/+tW45557Jvw969ati8bGxpFHW1tbMWUCAFStY3q35ssvvxwf+MAH4p577omZM2dOeLvVq1fHwMDAyKOvr+8YVgkAkI7jiuk8c+bMqKuri3379o1q37dvX8yaNWtM/6effjqeffbZWLhw4Ujb0NBQ4YuPOy527twZb3vb28ZsV19fH/X19cWUBgBQE4oaOZs+fXrMnTs3Nm3aNNI2NDQUmzZtinnz5o3pf95558WPfvSj2LFjx8jjT/7kT+Lyyy+PHTt2OF0JAPAmRY2cRUSsWrUqli5dGpdeemlcdtll0dPTE/v3749ly5ZFRMR1110XLS0tsW7dupgxY0ZccMEFo7Y/5ZRTIiLGtAMAcBThbMmSJfHCCy/EmjVrYu/evXHxxRfHww8/PHKTwK5du2LaNAsPAAAcjVyWZVmliziSwcHBaGxsjIGBgWhoaKh0OQAARSkmyxjiAgBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEnJcpQsgIfl8xNatEf39Ec3NEZ2dEXV1la4KAKYU4YyC3t6IFSsidu9+o621NeLOOyO6uytXFwBMMU5rUghmixePDmYREXv2FNp7eytTFwBMQcLZVJfPF0bMsmzse8NtK1cW+gEAx5xwNtVt3Tp2xOxgWRbR11foBwAcc8LZVNffX95+AEBJhLOprrm5vP0AgJIIZ1NdZ2fhrsxcbvz3c7mItrZCPwDgmBPOprq6usJ0GRFjA9rw654e850BwCQRzijMY7ZxY0RLy+j21tZCu3nOAGDSmISWgu7uiEWLrBAAABUmnPGGurqI+fMrXQUATGlOawIAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhAhnAAAJEc4AABIinAEAJEQ4AwBIiHAGAJAQ4QwAICHCGQBAQoQzAICECGcAAAkRzgAAEiKcAQAk5LhKF1Az8vmIrVsj+vsjmpsjOjsj6uoqXRUAUGWEs3Lo7Y1YsSJi9+432lpbI+68M6K7u3J1AQBVx2nNUvX2RixePDqYRUTs2VNo7+2d2Ofk8xFbtkTce2/hOZ8vd6UAQBUQzkqRzxdGzLJs7HvDbStXHjlo9fZGtLdHXH55xLXXFp7b2yce7ACAmiGclWLr1rEjZgfLsoi+vkK/QynXyBsAUBOEs1L095fWr1wjbwBAzRDOStHcXFq/coy8AQA1RTgrRWdn4a7MXG7893O5iLa2Qr/xlDryBgDUHOGsFHV1hekyIsYGtOHXPT2Hnu+s1JE3AKDmCGel6u6O2LgxoqVldHtra6H9cPOclTryBgDUHJPQlkN3d8SiRcWvEDA88rZ4cSGIHXxjwERG3gCAmiOclUtdXcT8+cVvNzzyNt4KAz09xa0wYAkpAKh6wlkKjnbk7WCWkAKAmnBU15ytX78+2tvbY8aMGdHR0RGPP/74Ifvec8890dnZGaeeemqceuqp0dXVddj+U9bwyNs11xSeiw1mJrIFgJpQdDi7//77Y9WqVbF27dp44oknYs6cObFgwYJ4/vnnx+2/ZcuWuOaaa2Lz5s2xbdu2aGtriyuvvDL27NlTcvGEiWwBoMbksmy8v+qH1tHREe94xzvirrvuioiIoaGhaGtri4997GNx8803H3H7fD4fp556atx1111x3XXXTeg7BwcHo7GxMQYGBqKhoaGYcmvfli2FtTiPZPPmo7smDgAoWTFZpqiRswMHDsT27dujq6vrjQ+YNi26urpi27ZtE/qMV155JV5//fU47bTTDtnntddei8HBwVEPDsFEtgBQU4oKZy+++GLk8/loamoa1d7U1BR79+6d0GfcdNNNMXv27FEB783WrVsXjY2NI4+2trZiypxaTGQLADVlUiehvf322+O+++6LBx54IGbMmHHIfqtXr46BgYGRR19f3yRWWWVMZAsANaWocDZz5syoq6uLffv2jWrft29fzJo167Db/u3f/m3cfvvt8e1vfzsuuuiiw/atr6+PhoaGUQ8OodQlpACApBQVzqZPnx5z586NTZs2jbQNDQ3Fpk2bYt68eYfc7o477ojPfvaz8fDDD8ell1569NUyvlKWkAIAklL0JLSrVq2KpUuXxqWXXhqXXXZZ9PT0xP79+2PZsmUREXHddddFS0tLrFu3LiIi/uZv/ibWrFkTGzZsiPb29pFr00466aQ46aSTyvhTprhyTGQLAFRc0eFsyZIl8cILL8SaNWti7969cfHFF8fDDz88cpPArl27Ytq0NwbkvvzlL8eBAwdi8eLFoz5n7dq18ZnPfKa06hntaJeQAgCSUfQ8Z5VgnjMAoJods3nOAAA4toQzAICECGcAAAkRzgAAEiKcAQAkRDgDAEiIcAYAkBDhDAAgIcIZAEBChDMAgIQUvbZmTcrnLRgOACRBOOvtjVixImL37jfaWlsj7rwzoru7cnUBAFPS1D6t2dsbsXjx6GAWEbFnT6G9t7cydQEAU9bUDWf5fGHELMvGvjfctnJloR8AwCSZuuFs69axI2YHy7KIvr5CPwCASTJ1w1l/f3n7AQCUwdQNZ83N5e0HAFAGUzecdXYW7srM5cZ/P5eLaGsr9AMAmCRTN5zV1RWmy4gYG9CGX/f0mO8MAJhUUzecRRTmMdu4MaKlZXR7a2uh3TxnAMAkMwltd3fEokVWCAAAkiCcRRSC2Pz5la4CAGCKn9YEAEiMcAYAkBDhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEKEMwCAhBxX6QImIsuyiIgYHByscCUAAMUbzjDDmeZwqiKcvfzyyxER0dbWVuFKAACO3ssvvxyNjY2H7ZPLJhLhKmxoaCiee+65OPnkkyOXy43bZ3BwMNra2qKvry8aGhomucLaYT+Wj31ZPvZlediP5WNfls9U2ZdZlsXLL78cs2fPjmnTDn9VWVWMnE2bNi1aW1sn1LehoaGm/8OdLPZj+diX5WNflof9WD72ZflMhX15pBGzYW4IAABIiHAGAJCQmgln9fX1sXbt2qivr690KVXNfiwf+7J87MvysB/Lx74sH/tyrKq4IQAAYKqomZEzAIBaIJwBACREOAMASIhwBgCQEOEMACAhNRHO1q9fH+3t7TFjxozo6OiIxx9/vNIlVZ3PfOYzkcvlRj3OO++8SpdVFb7zne/EwoULY/bs2ZHL5eJb3/rWqPezLIs1a9ZEc3NznHDCCdHV1RU/+9nPKlNswo60H//sz/5szDF61VVXVabYxK1bty7e8Y53xMknnxxnnHFGXH311bFz585RfV599dVYvnx5vOUtb4mTTjop3vve98a+ffsqVHGaJrIf58+fP+a4/PCHP1yhitP15S9/OS666KKRVQDmzZsX//mf/znyvuNxtKoPZ/fff3+sWrUq1q5dG0888UTMmTMnFixYEM8//3ylS6s6v/3bvx39/f0jj+9+97uVLqkq7N+/P+bMmRPr168f9/077rgj/u7v/i7uvvvu+P73vx+/8Ru/EQsWLIhXX311kitN25H2Y0TEVVddNeoYvffeeyexwurx2GOPxfLly+N73/tePProo/H666/HlVdeGfv37x/pc+ONN8a///u/xze/+c147LHH4rnnnovu7u4KVp2eiezHiIgbbrhh1HF5xx13VKjidLW2tsbtt98e27dvjx/84Afxh3/4h7Fo0aL4n//5n4hwPI6RVbnLLrssW758+cjrfD6fzZ49O1u3bl0Fq6o+a9euzebMmVPpMqpeRGQPPPDAyOuhoaFs1qxZ2ec///mRtpdeeimrr6/P7r333gpUWB3evB+zLMuWLl2aLVq0qCL1VLvnn38+i4jssccey7KscAwef/zx2Te/+c2RPj/5yU+yiMi2bdtWqTKT9+b9mGVZ9gd/8AfZihUrKldUFTv11FOzr3zlK47HcVT1yNmBAwdi+/bt0dXVNdI2bdq06Orqim3btlWwsur0s5/9LGbPnh1vfetb4/3vf3/s2rWr0iVVvWeeeSb27t076hhtbGyMjo4Ox+hR2LJlS5xxxhlx7rnnxkc+8pH4xS9+UemSqsLAwEBERJx22mkREbF9+/Z4/fXXRx2X5513Xpx55pmOy8N4834c9s///M8xc+bMuOCCC2L16tXxyiuvVKK8qpHP5+O+++6L/fv3x7x58xyP4ziu0gWU4sUXX4x8Ph9NTU2j2puamuLJJ5+sUFXVqaOjI77+9a/HueeeG/39/XHrrbdGZ2dn/PjHP46TTz650uVVrb1790ZEjHuMDr/HxFx11VXR3d0dZ599djz99NPxyU9+Mt797nfHtm3boq6urtLlJWtoaChWrlwZ73znO+OCCy6IiMJxOX369DjllFNG9XVcHtp4+zEi4tprr42zzjorZs+eHT/84Q/jpptuip07d0Zvb28Fq03Tj370o5g3b168+uqrcdJJJ8UDDzwQ559/fuzYscPx+CZVHc4on3e/+90j/77ooouio6MjzjrrrPjGN74R119/fQUrg4L3ve99I/++8MIL46KLLoq3ve1tsWXLlrjiiisqWFnali9fHj/+8Y9dQ1qiQ+3HD33oQyP/vvDCC6O5uTmuuOKKePrpp+Ntb3vbZJeZtHPPPTd27NgRAwMDsXHjxli6dGk89thjlS4rSVV9WnPmzJlRV1c35o6Offv2xaxZsypUVW045ZRT4u1vf3s89dRTlS6lqg0fh47R8nvrW98aM2fOdIwexkc/+tH4j//4j9i8eXO0traOtM+aNSsOHDgQL7300qj+jsvxHWo/jqejoyMiwnE5junTp8c555wTc+fOjXXr1sWcOXPizjvvdDyOo6rD2fTp02Pu3LmxadOmkbahoaHYtGlTzJs3r4KVVb9f/vKX8fTTT0dzc3OlS6lqZ599dsyaNWvUMTo4OBjf//73HaMl2r17d/ziF79wjI4jy7L46Ec/Gg888ED813/9V5x99tmj3p87d24cf/zxo47LnTt3xq5duxyXBznSfhzPjh07IiIclxMwNDQUr732muNxHFV/WnPVqlWxdOnSuPTSS+Oyyy6Lnp6e2L9/fyxbtqzSpVWVj3/847Fw4cI466yz4rnnnou1a9dGXV1dXHPNNZUuLXm//OUvR/2/5GeeeSZ27NgRp512Wpx55pmxcuXK+NznPhe/+Zu/GWeffXbccsstMXv27Lj66qsrV3SCDrcfTzvttLj11lvjve99b8yaNSuefvrp+MQnPhHnnHNOLFiwoIJVp2n58uWxYcOG+Nd//dc4+eSTR67baWxsjBNOOCEaGxvj+uuvj1WrVsVpp50WDQ0N8bGPfSzmzZsXv/u7v1vh6tNxpP349NNPx4YNG+I973lPvOUtb4kf/vCHceONN8a73vWuuOiiiypcfVpWr14d7373u+PMM8+Ml19+OTZs2BBbtmyJRx55xPE4nkrfLloOf//3f5+deeaZ2fTp07PLLrss+973vlfpkqrOkiVLsubm5mz69OlZS0tLtmTJkuypp56qdFlVYfPmzVlEjHksXbo0y7LCdBq33HJL1tTUlNXX12dXXHFFtnPnzsoWnaDD7cdXXnklu/LKK7PTTz89O/7447Ozzjoru+GGG7K9e/dWuuwkjbcfIyL7x3/8x5E+v/rVr7K/+Iu/yE499dTsxBNPzP70T/806+/vr1zRCTrSfty1a1f2rne9KzvttNOy+vr67Jxzzsn+8i//MhsYGKhs4Qn68z//8+yss87Kpk+fnp1++unZFVdckX37298eed/xOFouy7JsMsMgAACHVtXXnAEA1BrhDAAgIcIZAEBChDMAgIQIZwAACRHOAAASIpwBACREOAMASIhwBgCQEOEMACAhwhkAQEL+Hz3/r3KLd9QFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_graph(history):\n",
    "    accuracy = history.history['acc']\n",
    "    val_accuracy = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(epochs, accuracy, 'ro', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    # loss 및 val_loss 데이터의 크기를 epochs에 맞게 조정\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e45d7dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 526 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmh\\AppData\\Local\\Temp\\ipykernel_13784\\2171007069.py:13: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(testGen)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007644017692655325, 0.9942965507507324]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootPath = './dataset/train'\n",
    "\n",
    "\n",
    "testGenerator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "testGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(rootPath, 'digital_img'),\n",
    "    target_size=(64, 64),\n",
    ")\n",
    "\n",
    "model.evaluate_generator(testGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c55c033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# 이미지 열기\n",
    "img_path = 'd1_1_0.png'\n",
    "i = Image.open(img_path)\n",
    "\n",
    "# 이미지를 NumPy 배열로 변환\n",
    "img_np = np.array(i)\n",
    "\n",
    "# img_np와 같은 형태의 랜덤 행렬 생성\n",
    "#r = np.random.randint(-30, 30, size=img_np.shape)\n",
    "\n",
    "# 벡터화된 연산을 사용하여 img_np 업데이트\n",
    "#img_np = img_np - r\n",
    "\n",
    "# 값이 이미지 범위 [0, 255] 내에 있도록 클립\n",
    "#img_np = np.clip(img_np, 0, 255)\n",
    "\n",
    "# 업데이트된 NumPy 배열을 이미지로 변환\n",
    "#n = Image.fromarray(img_np.astype(np.uint8))\n",
    "\n",
    "# 수정된 이미지 보기\n",
    "#n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56267e4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16384 into shape (1,64,64,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m resized_img_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(array_to_img(img_np)\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)))\n\u001b[0;32m     14\u001b[0m resized_img_np \u001b[38;5;241m=\u001b[39m resized_img_np \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(resized_img_np\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m     18\u001b[0m predicted_class_prob \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(result)  \u001b[38;5;66;03m# 최댓값을 찾음\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 16384 into shape (1,64,64,3)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "import numpy as np\n",
    "\n",
    "img_path = './pred/pre4.png'\n",
    "i = Image.open(img_path)\n",
    "\n",
    "img_np = np.array(i)\n",
    "\n",
    "# img_np가 1280 * 1280 이미지인 것으로 가정합니다.\n",
    "\n",
    "resized_img_np = np.array(array_to_img(img_np).resize((64, 64)))\n",
    "resized_img_np = resized_img_np / 255.0\n",
    "\n",
    "result = model.predict(resized_img_np.reshape(1, 64, 64, 3))\n",
    "print(result)\n",
    "predicted_class_prob = np.max(result)  # 최댓값을 찾음\n",
    "predicted_class_index = np.argmax(result)  # 최댓값의 인덱스를 찾음\n",
    "print(label_to_class[predicted_class_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
